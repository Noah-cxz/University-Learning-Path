{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f869e6",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389be9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e0c90",
   "metadata": {},
   "source": [
    "# Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f560c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除空行与浮点化操作\n",
    "data = pd.read_csv('../Data/aiops_data.csv')\n",
    "_data = data.copy()\n",
    "_data = _data.dropna()\n",
    "_data = _data.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "6ea4d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分出90个样本作为测试集\n",
    "# 划分出2360个样本作为训练集\n",
    "sample_num = 30\n",
    "test_index = []\n",
    "\n",
    "import random\n",
    "random.seed( 10 )\n",
    "\n",
    "for a in range(3): \n",
    "    b = np.array( _data[_data[str(a+1)]==1].index.tolist() )\n",
    "    sample_list = [i for i in range(len(b))]\n",
    "    sample_list = random.sample(sample_list, sample_num)\n",
    "    test_index.append(b[sample_list])\n",
    "c = np.concatenate(test_index)\n",
    "test = _data.loc[c,:]\n",
    "train = _data.drop(index=c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1bf0a643",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = test[['1','2','3','4','5','6']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b2e33",
   "metadata": {},
   "source": [
    "# likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "474faf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormalPara(X): # NomalPara接受一组array\n",
    "    return np.mean(X,axis=0), np.cov(X.T)\n",
    "\n",
    "# 取样：root=1和root=0\n",
    "R1_1 = train[train['1']==1]\n",
    "R1_0 = train[train['1']==0]\n",
    "R2_1 = train[train['2']==1]\n",
    "R2_0 = train[train['2']==0]\n",
    "R3_1 = train[train['3']==1]\n",
    "R3_0 = train[train['3']==0]\n",
    "# 取出有效的特征\n",
    "R1_1 = R1_1[['feature15','feature13']]\n",
    "R1_0 = R1_0[['feature15','feature13']]\n",
    "R2_1 = R2_1[[\\\n",
    "    \"feature19\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature28_0\", \"feature28_1\",\"feature28_2\",  \"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",  \"feature36_3\",\"feature36_4\", \"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]]\n",
    "R2_0 = R2_0[[\\\n",
    "    \"feature19\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature28_0\", \"feature28_1\",\"feature28_2\",  \"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",  \"feature36_3\",\"feature36_4\", \"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]]\n",
    "R3_1 = R3_1[[\\\n",
    "    \"feature60\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature20_0\",\"feature20_1\",\"feature20_2\",\"feature20_3\",\"feature20_4\", \"feature20_5\",\"feature20_6\",\"feature20_7\", \n",
    "    \"feature28_0\",\"feature28_1\",\"feature28_2\",\"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",\"feature36_3\",\"feature36_4\",\"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]]\n",
    "R3_0 = R3_0[[\\\n",
    "    \"feature60\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature20_0\",\"feature20_1\",\"feature20_2\",\"feature20_3\",\"feature20_4\", \"feature20_5\",\"feature20_6\",\"feature20_7\", \n",
    "    \"feature28_0\",\"feature28_1\",\"feature28_2\",\"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",\"feature36_3\",\"feature36_4\",\"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]]\n",
    "# 按列计算均值；计算属性之间的协方差\n",
    "mu_R1_0,cov_R1_0 = NormalPara(R1_0.values)\n",
    "mu_R1_1,cov_R1_1 = NormalPara(R1_1.values)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "R1_pdf.append(multivariate_normal(mu_R1_0,cov_R1_0))\n",
    "R1_pdf.append(multivariate_normal(mu_R1_1,cov_R1_1))\n",
    "R1_pdf,R2_pdf,R3_pdf=[],[],[]\n",
    "R2_pdf.append(multivariate_normal(mu_R2_0,cov_R2_0))\n",
    "R2_pdf.append(multivariate_normal(mu_R2_1,cov_R2_1+np.eye(32)*0.0000001))# 奇异矩阵添加约束\n",
    "R3_pdf.append(multivariate_normal(mu_R3_0,cov_R3_0))\n",
    "R3_pdf.append(multivariate_normal(mu_R3_1,cov_R3_1))\n",
    "\n",
    " # prior\n",
    "pri_R1, pri_R2, pri_R3 = [0.5,0.5],[0.5,0.5],[0.5,0.5]\n",
    "\n",
    "# pro_product()\n",
    "def pro_product(sample,r1,r2,r3):\n",
    "    likelihood1 = R1_pdf[r1].pdf(sample[['feature15','feature13']].values)\n",
    "    likelihood2 = R2_pdf[r2].pdf(sample[[\\\n",
    "    \"feature19\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature28_0\", \"feature28_1\",\"feature28_2\",  \"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",  \"feature36_3\",\"feature36_4\", \"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]].values)\n",
    "    likelihood3 = R3_pdf[r3].pdf(sample[[\\\n",
    "    \"feature60\",\\\n",
    "    \"feature61_0\", \"feature61_1\",\"feature61_2\",  \"feature61_3\",\"feature61_4\",\"feature61_5\",\"feature61_6\",\"feature61_7\",\\\n",
    "    \"feature69_0\", \"feature69_1\",\"feature69_2\",\"feature69_3\",\"feature69_4\",  \"feature69_5\",\"feature69_6\", \\\n",
    "    \"feature20_0\",\"feature20_1\",\"feature20_2\",\"feature20_3\",\"feature20_4\", \"feature20_5\",\"feature20_6\",\"feature20_7\", \n",
    "    \"feature28_0\",\"feature28_1\",\"feature28_2\",\"feature28_3\",\"feature28_4\",\"feature28_5\",\"feature28_6\",\"feature28_7\",\\\n",
    "    \"feature36_0\", \"feature36_1\",\"feature36_2\",\"feature36_3\",\"feature36_4\",\"feature36_5\",\"feature36_6\",\"feature36_7\"\\\n",
    "    ]].values)\n",
    "    return likelihood1*likelihood2*likelihood3*pri_R1[r1]*pri_R1[r2]*pri_R1[r3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613be28d",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8e20d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample):\n",
    "    record=[] \n",
    "    for r1 in range(2): \n",
    "        for r2 in range(2):\n",
    "            for r3 in range(2):\n",
    "                record.append([r1,r2,r3,pro_product(sample,r1,r2,r3)]) \n",
    "    record = np.array(record)\n",
    "    record[:,3] = record[:,3]/sum(record[:,3]) \n",
    "    return sum(record[record[:,0]==1][:,3]),sum(record[record[:,1]==1][:,3]),sum(record[record[:,2]==1][:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "dc4f701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.zeros([test.shape[0],6])\n",
    "for i in range(test.shape[0]):\n",
    "    pred[i,0], pred[i,1], pred[i,2] = predict(test[i:i+1])\n",
    "# 设立阈值\n",
    "pred = pred > 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8f0743b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4222222222222222"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plus=np.sum(pred*label,axis=1)\n",
    "minus=np.sum(pred*(1-label),axis=1)\n",
    "np.mean((plus-minus)/np.sum(label,axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
